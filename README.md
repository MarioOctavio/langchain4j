Gemini AI Studio â€“ IntegraÃ§Ã£o com Java Spring Boot

ğŸ“Œ VisÃ£o Geral

Este projeto demonstra como integrar o Gemini AI Studio (Google AI) com LangChain4j e Spring Boot para realizar anÃ¡lises das mÃ©tricas da aplicaÃ§Ã£o â€” como uso de JVM, CPU, requisiÃ§Ãµes HTTP, entre outras.


Inclui:

- ExposiÃ§Ã£o de mÃ©tricas via Spring Boot Actuator

- IntegraÃ§Ã£o com Prometheus e Grafana para visualizaÃ§Ã£o, utilizando docker-compose

ğŸ§© Estrutura e Classes Principais

O projeto possui duas classes centrais que definem o comportamento da integraÃ§Ã£o entre mÃ©tricas e inteligÃªncia artificial:

<br/>
ğŸ”§ CustomMetrics

ResponsÃ¡vel por definir e organizar as mÃ©tricas personalizadas que serÃ£o extraÃ­das do Prometheus.

ContÃ©m os nomes e descriÃ§Ãµes das mÃ©tricas que serÃ£o analisadas pela LLM.

Pode ser estendida para incluir novas mÃ©tricas conforme a necessidade da aplicaÃ§Ã£o.

<br/>
ğŸ¤– AssistantAiService

ResponsÃ¡vel por definir o prompt base que serÃ¡ enviado Ã  LLM (Gemini via LangChain4j), esta classe centraliza toda a lÃ³gica de interaÃ§Ã£o com o modelo de linguagem â€” desde a formataÃ§Ã£o da entrada atÃ© a interpretaÃ§Ã£o da resposta.

Em conjunto, a classe MetricService realiza a extraÃ§Ã£o das mÃ©tricas do Prometheus, utilizando como referÃªncia a estrutura e os identificadores definidos em CustomMetrics.

As mÃ©tricas extraÃ­das sÃ£o entÃ£o encaminhadas Ã  AssistantAiService, que as utiliza como entrada para a LLM, aplicando o prompt prÃ©-configurado para gerar anÃ¡lises inteligentes com base nos dados coletados.

<br/>
ğŸš€ Tecnologias Utilizadas

Java 17+

Spring Boot

LangChain4j

Gemini AI Studio

Prometheus

Grafana

Docker

Gradle

<br/>
âœ… PrÃ©-requisitos

Java 17 ou superior instalado

Docker instalado e em execuÃ§Ã£o

Conta ativa no Gemini AI Studio com uma API Key vÃ¡lida

<br/>
âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

1 - Clone o repositÃ³rio:

``` bash
  git clone <repo-url>
```

<br/>
2 - Configure a API Key do Gemini:

Edite o arquivo src/main/resources/application.properties e adicione sua chave:

CÃ³digo
gemini.api.key=INFORME_SUA_API_KEY_AQUI


<br/>
3 - Execute a aplicaÃ§Ã£o:

Inicie a classe principal LangChainGeminiApplication.java

<br/>
4 - Suba os serviÃ§os do Prometheus e Grafana:

Execute o comando abaixo na pasta que contÃ©m o docker-compose.yml (pode ser a raiz ou iac-empresas):

```bash
  docker-compose up -d
```
<br/>

ğŸ”— Endpoints Ãšteis

MÃ©tricas (Spring Boot Actuator): http://localhost:8080/actuator/metrics

Prometheus: http://localhost:9090/targets

Grafana: http://localhost:3000

<br/>
ğŸ“š ReferÃªncias

ğŸ“˜ DocumentaÃ§Ã£o oficial do LangChain4j: https://docs.langchain4j.dev/intro/

ğŸ¥ VÃ­deo introdutÃ³rio sobre LangChain com Gemini AI Studio: https://www.youtube.com/watch?v=A5i7D7RAPA4&t

ğŸ”‘ Gerar chave de API do Gemini AI Studio: https://aistudio.google.com/api-keys